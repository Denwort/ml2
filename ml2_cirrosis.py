# -*- coding: utf-8 -*-
"""ML2_Cirrosis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SYDoQhEM-W_M5Vx6_WbffDSfF6pVP8D8
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from matplotlib.lines import Line2D
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder

# Cargar el csv
def load():
  path="./cirrhosis.csv"
  df=pd.read_csv(path,delimiter=',')
  return df

# Analisis exploratorio
# Graficar una variables
def plotVariable(data):
  print(data.info())
  print(data.describe())
  plt.figure(figsize=(15,5))
  plt.plot(data['Status'])
  plt.title('Status.', fontsize=15)
  plt.ylabel('Status')
  plt.show()

# Grafico de barras variables categoricas
def analisisCategoricas(df):
  varCategoricas = df.select_dtypes(exclude=np.number).columns
  print("Categoricas: ", varCategoricas)
  n_vars = len(varCategoricas)
  n_cols = 3
  n_rows = (n_vars + n_cols - 1) // n_cols
  fig, axis = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 4))
  index = 0
  for i in range(n_rows):
    for j in range(n_cols):
      if index < n_vars:
        ax = sns.countplot(x=varCategoricas[index], data=df, ax=axis[i][j])
        if varCategoricas[index] in ['job']:
          for item in ax.get_xticklabels():
            item.set_rotation(15)
        for p in ax.patches:
          height = p.get_height()
          ax.text(p.get_x()+p.get_width()/2.,
            height + 3,
            '{:1.2f}%'.format(height/len(df)*100),
            ha="center")
        index += 1
      else:
        axis[i, j].set_visible(False)
  plt.tight_layout()
  plt.show()

# Histograma y diagrama de caja para variables numericas
def analisisNumericas(df):
  varNumericas = df.select_dtypes(include=np.number).columns
  print("Numericas: ", varNumericas)
  for numerica in varNumericas:
    fig, axes = plt.subplots(1, 2, figsize=(16, 4))
    df[numerica].plot.hist(bins=25, ax=axes[0])
    axes[0].set_title(f'Histograma de {numerica}', fontdict={'fontsize': 16})
    df[numerica].plot.box(ax=axes[1])
    axes[1].set_title(f'Boxplot de {numerica}', fontdict={'fontsize': 16})
    plt.show()
    print("\n")

# Analisis de nulos
def nullAnalysis(df):
  null_columns=df.isnull().any()
  print("Nulos en columnas:")
  print(null_columns)
  null_sum = df.isnull().sum()
  print("Suma de nulos:")
  print(null_sum)
def dropNAinDrug(df):
  df = df.dropna(subset=['Drug'])
  return df
def imputeWithMode(df):
  df=df.fillna(df.mode().iloc[0])
  return df
# Probar inputacion con MICE
def imputeWithMICE():
  pass

# Tratamiento de Outliers

def lof(X_scaled,iris):
    lof=LocalOutlierFactor(n_neighbors=3,contamination=0.1)
    y_pred=lof.fit_predict(X_scaled)
    novelty_scores=-lof.negative_outlier_factor_
    threshold=np.percentile(novelty_scores, 90)
    predicted_labels=np.where(y_pred==-1,1,0)
    anomaly_indices=np.where(y_pred==-1)[0]
    print("indices de las anomalias")
    print(anomaly_indices)
    print("datos clasificados como anomalias")
    print(iris.iloc[anomaly_indices])

# Encoding
def encodingCategoricasOneHot(df):
  cat_columns = df.select_dtypes(include=['object']).columns.tolist()

  # Inicializa el OneHotEncoder
  encoder = OneHotEncoder(sparse=False, drop='first')

  # Ajusta y transforma las columnas categóricas
  encoded_cols = pd.DataFrame(encoder.fit_transform(df[cat_columns]))

  # Añade los nombres de las columnas al DataFrame codificado
  encoded_cols.columns = encoder.get_feature_names_out(cat_columns)

  # Elimina las columnas originales y concatena las codificadas
  df = pd.concat([df.drop(columns=cat_columns), encoded_cols], axis=1)

  return df

def main():
    df = load()

    df = df.iloc[1:] # Dropear ID

    X = df.iloc[:, df.columns != 'Status'].values
    y = df.iloc[:, 2].values

    # Analisis exploratorio
    #analisisCategoricas(df)
    #analisisNumericas(df)

    # Tratamiento de nulos
    #nullAnalysis(df)
    df = dropNAinDrug(df) # el dataset recomienda dropear los Drug=null
    df = imputeWithMode(df) # el dataset recomienda imputar con Media, pero como son categpricas utilizo moda
    #nullAnalysis(df)

    # Tratamiento de outliers


    # Encoding

    # Escalamiento

main()